{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4edb383",
   "metadata": {},
   "source": [
    "# Food Recognition and Weight Estimation Model\n",
    "\n",
    "This notebook demonstrates how to use the food recognition and weight estimation model. The model uses a multi-task learning approach with a ResNet50 backbone to simultaneously perform food classification and weight estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88724188",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ba309",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision pandas numpy pillow scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1fd3b2",
   "metadata": {},
   "source": [
    "## 2. Import the Model\n",
    "\n",
    "The model has been combined into a single file `kaggle_model.py`. Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9aebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_model import MultiTaskNet, FoodDataset, prepare_data, parse_args, train_model, get_device\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4fe6a",
   "metadata": {},
   "source": [
    "## 3. Inference Function\n",
    "\n",
    "Let's define a function for inference that can be used with sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, model, idx_to_label, device):\n",
    "    \"\"\"Process a single image and return the predictions.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_image = image.copy()\n",
    "    \n",
    "    # Prepare image for model\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        class_logits, weight_pred = model(input_tensor)\n",
    "    \n",
    "    # Process classification results\n",
    "    probabilities = torch.nn.functional.softmax(class_logits, dim=1)\n",
    "    top_prob, top_class = torch.topk(probabilities, k=3, dim=1)\n",
    "    \n",
    "    # Convert to numpy for easier handling\n",
    "    top_classes = top_class.squeeze().cpu().numpy()\n",
    "    top_probs = top_prob.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Get the food labels and probabilities\n",
    "    food_predictions = [\n",
    "        {\n",
    "            \"label\": idx_to_label[idx], \n",
    "            \"probability\": float(prob)\n",
    "        }\n",
    "        for idx, prob in zip(top_classes, top_probs)\n",
    "    ]\n",
    "    \n",
    "    # Get weight prediction\n",
    "    predicted_weight = float(weight_pred.item())\n",
    "    \n",
    "    results = {\n",
    "        \"food_predictions\": food_predictions,\n",
    "        \"predicted_weight\": predicted_weight,\n",
    "        \"image_path\": image_path\n",
    "    }\n",
    "    \n",
    "    return results, original_image\n",
    "\n",
    "def visualize_results(image, results):\n",
    "    \"\"\"Visualize the inference results.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add text overlay with predictions\n",
    "    prediction_text = f\"Food: {results['food_predictions'][0]['label']} ({results['food_predictions'][0]['probability']:.2f})\\n\"\n",
    "    prediction_text += f\"Weight: {results['predicted_weight']:.1f}g\"\n",
    "    \n",
    "    plt.text(10, 30, prediction_text, color='white', fontsize=12, \n",
    "             bbox=dict(facecolor='black', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ce413",
   "metadata": {},
   "source": [
    "## 4. Loading the Model\n",
    "\n",
    "Now let's load a pretrained model if available, or train a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define path to the model (upload your pretrained model to Kaggle or use a new one)\n",
    "model_path = \"../input/food-model/best_model.pth\"  # Adjust this path based on your Kaggle dataset\n",
    "\n",
    "try:\n",
    "    # Try to load the model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    label_to_idx = checkpoint.get('label_to_idx', {})\n",
    "    idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
    "    \n",
    "    num_classes = len(label_to_idx)\n",
    "    model = MultiTaskNet(num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded successfully with {num_classes} food classes\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load model: {e}\")\n",
    "    print(\"You'll need to train a model or upload a pretrained one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d8531",
   "metadata": {},
   "source": [
    "## 5. Inference with Sample Images\n",
    "\n",
    "Let's use our model for inference on some sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752409f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image path - replace with your own image path\n",
    "sample_image_path = \"../input/food-images/pasta.jpg\"  # Adjust this path\n",
    "\n",
    "try:\n",
    "    results, image = process_image(sample_image_path, model, idx_to_label, device)\n",
    "    visualize_results(image, results)\n",
    "    \n",
    "    print(\"\\nTop 3 predictions:\")\n",
    "    for pred in results[\"food_predictions\"]:\n",
    "        print(f\"- {pred['label']}: {pred['probability']:.4f}\")\n",
    "    print(f\"Estimated weight: {results['predicted_weight']:.1f}g\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a5e6e",
   "metadata": {},
   "source": [
    "## 6. Training a New Model\n",
    "\n",
    "If you have your own dataset, you can train a new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25547faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for your Kaggle dataset\n",
    "csv_path = \"../input/food-dataset/food_labels.csv\"  # Adjust based on your data\n",
    "images_dir = \"../input/food-dataset/images\"  # Adjust based on your data\n",
    "model_dir = \"./models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Define training parameters\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "num_epochs = 5  # Reduced for demonstration purposes\n",
    "\n",
    "# Load and prepare data\n",
    "try:\n",
    "    train_dataloader, val_dataloader, label_to_idx = prepare_data(\n",
    "        csv_path, images_dir, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    num_classes = len(label_to_idx)\n",
    "    model = MultiTaskNet(num_classes)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define args object for the training function\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.lr = 1e-4\n",
    "    args = Args()\n",
    "    \n",
    "    # Train the model\n",
    "    training_logs = train_model(\n",
    "        model, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        device, \n",
    "        num_epochs, \n",
    "        model_dir\n",
    "    )\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe97c66",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results\n",
    "\n",
    "If you've trained a model, let's visualize the training metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_logs['epochs'], training_logs['train_loss'], label='Train Loss')\n",
    "    plt.plot(training_logs['epochs'], training_logs['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_logs['epochs'], training_logs['val_accuracy'], label='Accuracy')\n",
    "    plt.plot(training_logs['epochs'], training_logs['weight_mae'], label='Weight MAE (g)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Validation Metrics')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"No training logs available to visualize\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
