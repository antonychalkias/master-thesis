#!/usr/bin/env python3
"""
Combined model for food recognition and weight estimation.
This file was automatically generated by combining model.py, data.py, utils.py, and train.py.
"""

import torch.nn as nn
from torchvision.models import resnet50, ResNet50_Weights
from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
from torchvision import transforms
import torch
import os
import pandas as pd
import argparse
import json
import torch.optim as optim
import torch.multiprocessing as mp
from torch.optim.lr_scheduler import StepLR
from sklearn.metrics import accuracy_score, mean_absolute_error
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np


# ========================= model.py =========================
"""
Model architecture for food recognition and weight estimation.
"""

import torch.nn as nn
from torchvision.models import resnet50, ResNet50_Weights

class MultiTaskNet(nn.Module):
    """
    Multi-task neural network with two heads:
    - Classification head for food recognition
    - Regression head for weight estimation
    
    Uses ResNet50 as the backbone with pretrained weights.
    """
    def __init__(self, num_classes):
        super().__init__()
        
        # Load pretrained ResNet50 as backbone
        self.backbone = resnet50(weights=ResNet50_Weights.DEFAULT)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()  # Remove the final fully connected layer
        
        # Task-specific heads
        self.classifier = nn.Linear(num_features, num_classes)  # classification head
        self.regressor = nn.Linear(num_features, 1)             # regression head
    
    def forward(self, x):
        """
        Forward pass through the network
        
        Args:
            x: Input tensor of shape [batch_size, 3, height, width]
            
        Returns:
            class_logits: Classification logits of shape [batch_size, num_classes]
            weight_pred: Weight predictions of shape [batch_size]
        """
        features = self.backbone(x)
        class_logits = self.classifier(features)
        weight_pred = self.regressor(features).squeeze(1)
        return class_logits, weight_pred


# ========================= data.py =========================
"""
Data processing and loading for food recognition and weight estimation model.
"""

from torch.utils.data import Dataset, DataLoader, random_split
from PIL import Image
from torchvision import transforms
import torch
import os
import pandas as pd

class FoodDataset(Dataset):
    def __init__(self, dataframe, image_dir, transform=None):
        self.df = dataframe.reset_index(drop=True)
        self.image_dir = image_dir
        self.transform = transform if transform else transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225])
        ])

        # Cache for found paths to speed up loading
        self.path_cache = {}
    
    def __len__(self):
        return len(self.df)
    
    def _try_load_image(self, path, row):
        """Helper to attempt loading an image from a path"""
        try:
            image = Image.open(path).convert('RGB')
            image = self.transform(image)
            return image, torch.tensor(row['label_idx'], dtype=torch.long), torch.tensor(row['weight'], dtype=torch.float32)
        except Exception:
            return None
    
    def _create_placeholder(self, row):
        """Create a placeholder black image for missing files"""
        image = Image.new('RGB', (224, 224), color='black')
        image = self.transform(image)
        return image, torch.tensor(row['label_idx'], dtype=torch.long), torch.tensor(row['weight'], dtype=torch.float32)
    
    def _find_image_path(self, img_name):
        """Find the correct path for an image, handling different cases and extensions"""
        # Get base name without extension
        name_without_ext, _ = os.path.splitext(img_name)
        
        # 1. Try original path first
        original_path = os.path.join(self.image_dir, img_name)
        if os.path.exists(original_path):
            return original_path
            
        # 2. Try with common extensions
        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
            test_path = os.path.join(self.image_dir, name_without_ext + ext)
            if os.path.exists(test_path):
                return test_path
        
        # 3. Case-insensitive search
        try:
            name_lower = name_without_ext.lower()
            for file in os.listdir(self.image_dir):
                file_name, _ = os.path.splitext(file)
                if file_name.lower() == name_lower:
                    return os.path.join(self.image_dir, file)
        except Exception as e:
            print(f"Error during file search: {e}")
            
        # Not found
        return None
    
    def __getitem__(self, idx):
        try:
            row = self.df.iloc[idx]
            img_name = row['image_name']
            
            # Check cache first
            if img_name in self.path_cache:
                cached_path = self.path_cache[img_name]
                if cached_path == "PLACEHOLDER":
                    return self._create_placeholder(row)
                    
                result = self._try_load_image(cached_path, row)
                if result is not None:
                    return result
                # Path no longer valid, clear from cache
                del self.path_cache[img_name]
            
            # Try to find the image path
            img_path = self._find_image_path(img_name)
            
            if img_path:
                # Found a path, try to load it
                result = self._try_load_image(img_path, row)
                if result is not None:
                    self.path_cache[img_name] = img_path
                    return result
            
            # If we get here, image wasn't found or couldn't be loaded
            print(f"Warning: Image {img_name} not found or corrupted, using placeholder")
            self.path_cache[img_name] = "PLACEHOLDER"
            return self._create_placeholder(row)
            
        except Exception as e:
            print(f"Unexpected error for index {idx}: {e}")
            return self._create_placeholder(row)

def prepare_data(csv_path, images_dir, batch_size=16, num_workers=0):
    """
    Prepare data for training and validation
    
    Args:
        csv_path: Path to CSV file with annotations
        images_dir: Path to directory with images
        batch_size: Batch size for DataLoader
        num_workers: Number of workers for data loading
    
    Returns:
        train_dataloader: DataLoader for training data
        val_dataloader: DataLoader for validation data
        label_to_idx: Dictionary mapping labels to indices
    """
    # Load and process CSV
    try:
        df = pd.read_csv(csv_path, sep=';', quotechar='"')
        print(f"Successfully loaded {len(df)} records from {csv_path}")
    except Exception as e:
        print(f"Error loading CSV: {e}")
        raise
        
    # Create label-to-index mapping
    label_to_idx = {label: idx for idx, label in enumerate(df['labels'].unique())}
    df['label_idx'] = df['labels'].map(label_to_idx)

    print(f"Number of classes: {len(label_to_idx)}")
    print(df.head())

    # Create dataset
    dataset = FoodDataset(df, images_dir)
    print(f"Dataset size: {len(dataset)} images")

    # Split data into train and validation
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

    # Create dataloaders
    train_dataloader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers, 
        pin_memory=True
    )
    
    val_dataloader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers, 
        pin_memory=True
    )

    print(f"Training on {train_size} samples, validating on {val_size} samples")

    return train_dataloader, val_dataloader, label_to_idx


# ========================= utils.py =========================
"""
Utility functions for food recognition and weight estimation model.
"""

import os
import argparse

def parse_args():
    """
    Parse command-line arguments for the training script.
    
    Returns:
        args: Parsed arguments
    """
    parser = argparse.ArgumentParser(description="Train food recognition and weight estimation model")
    parser.add_argument("--csv_path", type=str, default=None, help="Path to the CSV file with annotations")
    parser.add_argument("--images_dir", type=str, default=None, help="Path to the directory with images")
    parser.add_argument("--epochs", type=int, default=20, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=16, help="Batch size for training")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate")
    parser.add_argument("--model_dir", type=str, default=None, help="Directory to save the model")
    parser.add_argument("--num_workers", type=int, default=0, help="Number of workers for data loading")
    return parser.parse_args()

def setup_paths(args):
    """
    Set up paths for CSV file, images directory, and model save directory.
    
    Args:
        args: Parsed command-line arguments
        
    Returns:
        args: Updated arguments with default paths set
    """
    # Get project root directory
    master_thesis_dir = "/kaggle/working"
    
    # Set default paths if not provided
    if args.csv_path is None:
        args.csv_path = os.path.join(master_thesis_dir, "csvfiles", "latest_lab.csv")
        # Check if file exists, if not try with the small test file
        if not os.path.exists(args.csv_path):
            print(f"Warning: CSV file not found at {args.csv_path}")
            # Try alternative path
            alternative_csv = os.path.join(master_thesis_dir, "csvfiles", "labels_latest_with_4_rows.csv")
            if os.path.exists(alternative_csv):
                print(f"Using alternative CSV file: {alternative_csv}")
                args.csv_path = alternative_csv
    
    if args.images_dir is None:
        args.images_dir = os.path.join(master_thesis_dir, "images")
    
    if args.model_dir is None:
        args.model_dir = os.path.join(master_thesis_dir, "models")
    
    print(f"CSV path: {args.csv_path}")
    print(f"Images directory: {args.images_dir}")
    print(f"Model save directory: {args.model_dir}")
    
    # Create model save directory
    os.makedirs(args.model_dir, exist_ok=True)
    
    return args

def get_device():
    """
    Get the best available device for training (CUDA, MPS, or CPU).
    
    Returns:
        device: PyTorch device
    """
    import torch
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    if torch.backends.mps.is_available():
        device = torch.device("mps")
    else:
        device = torch.device("cpu")

    print(f"Using device: {device}")
    return device


# ========================= train.py =========================
"""
Training script for food recognition and weight estimation model.
"""

import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp
from torch.optim.lr_scheduler import StepLR
from sklearn.metrics import accuracy_score, mean_absolute_error





def train_model(model, train_dataloader, val_dataloader, device, num_epochs, model_save_dir):
    """
    Train the model and save the best checkpoint
    
    Args:
        model: Model to train
        train_dataloader: DataLoader for training data
        val_dataloader: DataLoader for validation data
        device: Device to use for training
        num_epochs: Number of epochs to train for
        model_save_dir: Directory to save the model
    
    Returns:
        training_logs: Dictionary containing training metrics
    """
    # Loss functions
    criterion_class = nn.CrossEntropyLoss()
    criterion_weight = nn.MSELoss()
    
    # Optimizer
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)
    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)
    
    # Metrics tracking
    best_val_loss = float('inf')
    training_logs = {
        "epochs": [],
        "train_loss": [],
        "val_loss": [],
        "val_accuracy": [],
        "weight_mae": []
    }

    print(f"Optimizer: Adam with learning rate {args.lr}, weight decay 1e-5")
    print(f"Starting training for {num_epochs} epochs...")

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        running_train_loss = 0.0
        
        for images, labels, weights in train_dataloader:
            images = images.to(device)
            labels = labels.to(device)
            weights = weights.to(device)

            optimizer.zero_grad()
            
            outputs_class, outputs_weight = model(images)
            
            loss_class = criterion_class(outputs_class, labels)
            loss_weight = criterion_weight(outputs_weight, weights)
            
            # Weighted loss - emphasizes classification a bit more than regression
            total_loss = 0.7 * loss_class + 0.3 * loss_weight

            total_loss.backward()
            optimizer.step()
            
            running_train_loss += total_loss.item()
        
        avg_train_loss = running_train_loss / len(train_dataloader)
        
        # Validation phase
        model.eval()
        running_val_loss = 0.0
        all_preds = []
        all_labels = []
        all_weight_preds = []
        all_weight_true = []
        
        with torch.no_grad():
            for images, labels, weights in val_dataloader:
                images = images.to(device)
                labels = labels.to(device)
                weights = weights.to(device)
                
                outputs_class, outputs_weight = model(images)
                
                loss_class = criterion_class(outputs_class, labels)
                loss_weight = criterion_weight(outputs_weight, weights)
                
                total_loss = loss_class + loss_weight
                running_val_loss += total_loss.item()
                
                _, predicted = torch.max(outputs_class, 1)
                
                all_preds.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_weight_preds.extend(outputs_weight.cpu().numpy())
                all_weight_true.extend(weights.cpu().numpy())
        
        avg_val_loss = running_val_loss / len(val_dataloader)
        val_accuracy = accuracy_score(all_labels, all_preds)
        val_mae = mean_absolute_error(all_weight_true, all_weight_preds)
        
        print(f"Epoch {epoch+1}/{num_epochs}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, "
              f"Val Acc = {val_accuracy:.4f}, Weight MAE = {val_mae:.2f}g")
        
        # Save epoch metrics to log
        training_logs["epochs"].append(epoch + 1)
        training_logs["train_loss"].append(avg_train_loss)
        training_logs["val_loss"].append(avg_val_loss)
        training_logs["val_accuracy"].append(val_accuracy)
        training_logs["weight_mae"].append(val_mae)

        # Save the best model
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            model_path = os.path.join(model_save_dir, "best_model.pth")
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': best_val_loss,
                'val_accuracy': val_accuracy,
                'val_mae': val_mae,
                'label_to_idx': label_to_idx
            }, model_path)
            print(f"Model saved to {model_path}")
        
        scheduler.step()

    return training_logs

if __name__ == '__main__':
    # Required for multiprocessing on macOS
    mp.set_start_method('spawn', force=True)
    
    # Define paths inside Kaggle
    DATA_PATH = "/kaggle/input/thesis-data"
    args = argparse.Namespace(
        csv_path=f"{DATA_PATH}/csvfiles/latest_lab.csv",
        images_dir=f"{DATA_PATH}/images",
        model_dir="/kaggle/working",  # This is where Kaggle lets you write files
        epochs=20,
        batch_size=16,
        lr=1e-4,
        num_workers=2
    )

    
    # Prepare data
    train_dataloader, val_dataloader, label_to_idx = prepare_data(
        args.csv_path, 
        args.images_dir, 
        batch_size=args.batch_size, 
        num_workers=args.num_workers
    )
    
    # Get device (CUDA, MPS, or CPU)
    device = get_device()
    
    # Initialize model
    num_classes = len(label_to_idx)
    model = MultiTaskNet(num_classes)
    model.to(device)
    
    # Train the model
    training_logs = train_model(
        model, 
        train_dataloader, 
        val_dataloader, 
        device, 
        args.epochs, 
        args.model_dir
    )
    
    # Save training log as JSON
    log_path = os.path.join(args.model_dir, "training_log.json")
    with open(log_path, "w") as f:
        json.dump(training_logs, f, indent=4)
    print(f"Training log saved to {log_path}")
    
    print("Training completed!")


# ========================= infer.py =========================
"""
Inference script for food recognition and weight estimation model.
"""

import argparse
import os
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import json


def parse_args():
    parser = argparse.ArgumentParser(description="Food recognition and weight estimation inference")
    parser.add_argument("--model_path", type=str, required=True, help="Path to the trained model")
    parser.add_argument("--image_path", type=str, default=None, help="Path to a single food image")
    parser.add_argument("--images_dir", type=str, default=None, help="Directory with multiple food images")
    parser.add_argument("--output_dir", type=str, default="results", help="Directory to save results")
    return parser.parse_args()

def load_model(model_path):
    """Load the trained model and label mapping."""
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
    
    label_to_idx = checkpoint.get('label_to_idx', {})
    idx_to_label = {v: k for k, v in label_to_idx.items()}
    
    num_classes = len(label_to_idx)
    model = MultiTaskNet(num_classes)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    return model, idx_to_label

def process_image(image_path, model, idx_to_label, device):
    """Process a single image and return the predictions."""
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    image = Image.open(image_path).convert('RGB')
    original_image = image.copy()
    
    # Prepare image for model
    input_tensor = transform(image).unsqueeze(0).to(device)
    
    # Get predictions
    with torch.no_grad():
        class_logits, weight_pred = model(input_tensor)
    
    # Process classification results
    probabilities = torch.nn.functional.softmax(class_logits, dim=1)
    top_prob, top_class = torch.topk(probabilities, k=3, dim=1)
    
    # Convert to numpy for easier handling
    top_classes = top_class.squeeze().cpu().numpy()
    top_probs = top_prob.squeeze().cpu().numpy()
    
    # Get the food labels and probabilities
    food_predictions = [
        {
            "label": idx_to_label[idx], 
            "probability": float(prob)
        }
        for idx, prob in zip(top_classes, top_probs)
    ]
    
    # Get weight prediction
    predicted_weight = float(weight_pred.item())
    
    results = {
        "food_predictions": food_predictions,
        "predicted_weight": predicted_weight,
        "image_path": image_path
    }
    
    return results, original_image

def visualize_results(image, results, output_path):
    """Create and save a visualization of the results."""
    plt.figure(figsize=(10, 8))
    plt.imshow(image)
    plt.axis('off')
    
    # Add text overlay with predictions
    prediction_text = f"Food: {results['food_predictions'][0]['label']} ({results['food_predictions'][0]['probability']:.2f})\n"
    prediction_text += f"Weight: {results['predicted_weight']:.1f}g"
    
    plt.text(10, 30, prediction_text, color='white', fontsize=12, 
             bbox=dict(facecolor='black', alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(output_path)
    plt.close()
    
    print(f"Results saved to {output_path}")

def main():
    args = parse_args()
    
    # Create output directory if it doesn't exist
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Load model
    model, idx_to_label = load_model(args.model_path)
    model.to(device)
    
    if args.image_path:
        # Process a single image
        image_name = os.path.basename(args.image_path)
        results, original_image = process_image(args.image_path, model, idx_to_label, device)
        
        # Save results
        output_path = os.path.join(args.output_dir, f"{os.path.splitext(image_name)[0]}_result.jpg")
        visualize_results(original_image, results, output_path)
        
        # Save JSON with detailed results
        json_path = os.path.join(args.output_dir, f"{os.path.splitext(image_name)[0]}_result.json")
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=4)
            
    elif args.images_dir:
        # Process all images in the directory
        image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']
        image_files = [f for f in os.listdir(args.images_dir) 
                      if any(f.lower().endswith(ext) for ext in image_extensions)]
        
        print(f"Found {len(image_files)} images to process")
        
        for image_file in image_files:
            image_path = os.path.join(args.images_dir, image_file)
            results, original_image = process_image(image_path, model, idx_to_label, device)
            
            # Save results
            output_path = os.path.join(args.output_dir, f"{os.path.splitext(image_file)[0]}_result.jpg")
            visualize_results(original_image, results, output_path)
            
            # Save JSON with detailed results
            json_path = os.path.join(args.output_dir, f"{os.path.splitext(image_file)[0]}_result.json")
            with open(json_path, 'w') as f:
                json.dump(results, f, indent=4)
            
            print(f"Processed {image_file}")
    else:
        print("Please provide either --image_path or --images_dir")

if __name__ == "__main__":
    main()
