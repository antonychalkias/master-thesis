{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e569f4",
   "metadata": {},
   "source": [
    "# Improved Food Recognition & Weight Estimation Model\n",
    "\n",
    "This notebook implements a multi-task learning model for food recognition and weight estimation with advanced training utilities:\n",
    "- Early stopping\n",
    "- Top-N model saving\n",
    "- Resume from checkpoint capability\n",
    "- Adaptive learning rate scheduling\n",
    "- Training visualization\n",
    "\n",
    "The model uses EfficientNet-B0 as the backbone with separate heads for classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252e68c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa941c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "try:\n",
    "    from one_cycle_lr import OneCycleLR as CustomOneCycleLR\n",
    "except ImportError:\n",
    "    CustomOneCycleLR = None\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2db620",
   "metadata": {},
   "source": [
    "## 2. Model Architecture\n",
    "\n",
    "This model architecture combines a shared EfficientNet-B0 backbone with separate heads for food classification and weight estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Load pretrained EfficientNet-B0\n",
    "        self.backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "        # Get the number of features before the classification layer\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "\n",
    "        # Remove original classifier head\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # Add multitask heads\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        self.regressor = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        class_logits = self.classifier(features)\n",
    "        weight_pred = self.regressor(features).squeeze(1)\n",
    "        return class_logits, weight_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd9640",
   "metadata": {},
   "source": [
    "## 3. Dataset Implementation\n",
    "\n",
    "The `FoodDataset` class handles loading and preprocessing food images along with their classification labels and weight information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Cache for found paths to speed up loading\n",
    "        self.path_cache = {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _try_load_image(self, path, row):\n",
    "        \"\"\"Helper to attempt loading an image from a path\"\"\"\n",
    "        try:\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            image = self.transform(image)\n",
    "            return image, torch.tensor(row['label_idx'], dtype=torch.long), torch.tensor(row['weight'], dtype=torch.float32)\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def _create_placeholder(self, row):\n",
    "        \"\"\"Create a placeholder black image for missing files\"\"\"\n",
    "        image = Image.new('RGB', (224, 224), color='black')\n",
    "        image = self.transform(image)\n",
    "        return image, torch.tensor(row['label_idx'], dtype=torch.long), torch.tensor(row['weight'], dtype=torch.float32)\n",
    "    \n",
    "    def _find_image_path(self, img_name):\n",
    "        \"\"\"Find the correct path for an image, handling different cases and extensions\"\"\"\n",
    "        # Get base name without extension\n",
    "        name_without_ext, _ = os.path.splitext(img_name)\n",
    "        \n",
    "        # 1. Try original path first\n",
    "        original_path = os.path.join(self.image_dir, img_name)\n",
    "        if os.path.exists(original_path):\n",
    "            return original_path\n",
    "            \n",
    "        # 2. Try with common extensions\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
    "            test_path = os.path.join(self.image_dir, name_without_ext + ext)\n",
    "            if os.path.exists(test_path):\n",
    "                return test_path\n",
    "        \n",
    "        # 3. Case-insensitive search\n",
    "        try:\n",
    "            name_lower = name_without_ext.lower()\n",
    "            for file in os.listdir(self.image_dir):\n",
    "                file_name, _ = os.path.splitext(file)\n",
    "                if file_name.lower() == name_lower:\n",
    "                    return os.path.join(self.image_dir, file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during file search: {e}\")\n",
    "            \n",
    "        # Not found\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "            img_name = row['image_name']\n",
    "            \n",
    "            # Check cache first\n",
    "            if img_name in self.path_cache:\n",
    "                cached_path = self.path_cache[img_name]\n",
    "                if cached_path == \"PLACEHOLDER\":\n",
    "                    return self._create_placeholder(row)\n",
    "                    \n",
    "                result = self._try_load_image(cached_path, row)\n",
    "                if result is not None:\n",
    "                    return result\n",
    "                # Path no longer valid, clear from cache\n",
    "                del self.path_cache[img_name]\n",
    "            \n",
    "            # Try to find the image path\n",
    "            img_path = self._find_image_path(img_name)\n",
    "            \n",
    "            if img_path:\n",
    "                # Found a path, try to load it\n",
    "                result = self._try_load_image(img_path, row)\n",
    "                if result is not None:\n",
    "                    self.path_cache[img_name] = img_path\n",
    "                    return result\n",
    "            \n",
    "            # If we get here, image wasn't found or couldn't be loaded\n",
    "            print(f\"Warning: Image {img_name} not found or corrupted, using placeholder\")\n",
    "            self.path_cache[img_name] = \"PLACEHOLDER\"\n",
    "            return self._create_placeholder(row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for index {idx}: {e}\")\n",
    "            return self._create_placeholder(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb047e",
   "metadata": {},
   "source": [
    "## 4. Data Preparation Functions\n",
    "\n",
    "These functions prepare the data for training, including loading the CSV file, creating label mappings, and setting up train/validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc80235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(csv_path, images_dir, batch_size=16, num_workers=0):\n",
    "    \"\"\"Prepare data for training and validation\"\"\"\n",
    "    # Load and process CSV\n",
    "    df = pd.read_csv(csv_path, sep=';', quotechar='\"')\n",
    "    print(f\"Successfully loaded {len(df)} records from {csv_path}\")\n",
    "\n",
    "    # Create label-to-index mapping\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(df['labels'].unique())}\n",
    "    df['label_idx'] = df['labels'].map(label_to_idx)\n",
    "\n",
    "    print(f\"Number of classes: {len(label_to_idx)}\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Define train and val transforms separately\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create base dataset with dummy transform (we'll override it below)\n",
    "    base_dataset = FoodDataset(df, images_dir, transform=None)\n",
    "\n",
    "    # Split into train/val\n",
    "    train_size = int(0.8 * len(base_dataset))\n",
    "    val_size = len(base_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(base_dataset, [train_size, val_size])\n",
    "\n",
    "    # Assign correct transforms\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = val_transform\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"Training on {train_size} samples, validating on {val_size} samples\")\n",
    "\n",
    "    return train_dataloader, val_dataloader, label_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e186d9",
   "metadata": {},
   "source": [
    "## 5. Learning Rate Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, lr_strategy, num_epochs, steps_per_epoch, lr, min_lr=1e-6):\n",
    "    if lr_strategy == 'one_cycle':\n",
    "        if CustomOneCycleLR is not None:\n",
    "            return CustomOneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=lr,\n",
    "                total_epochs=num_epochs,\n",
    "                steps_per_epoch=steps_per_epoch\n",
    "            )\n",
    "        else:\n",
    "            return torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=lr,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=num_epochs\n",
    "            )\n",
    "    elif lr_strategy == 'cosine':\n",
    "        return CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=min_lr)\n",
    "    elif lr_strategy == 'step':\n",
    "        return StepLR(optimizer, step_size=5, gamma=0.75)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad535af",
   "metadata": {},
   "source": [
    "## 6. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a661bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_one_epoch(model, dataloader, optimizer, scheduler, device, criterion_class, criterion_weight, lr_strategy):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, weights in dataloader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        weights = weights.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        outputs_class, outputs_weight = model(images)\n",
    "        loss_class = criterion_class(outputs_class, labels)\n",
    "        loss_weight = criterion_weight(outputs_weight, weights)\n",
    "        total_loss = 0.7 * loss_class + 0.3 * loss_weight\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None and lr_strategy == 'one_cycle':\n",
    "            scheduler.step()\n",
    "        running_loss += total_loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def _validate_one_epoch(model, dataloader, device, criterion_class, criterion_weight):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    all_weight_preds, all_weight_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, weights in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "            outputs_class, outputs_weight = model(images)\n",
    "            loss_class = criterion_class(outputs_class, labels)\n",
    "            loss_weight = criterion_weight(outputs_weight, weights)\n",
    "            total_loss = loss_class + loss_weight\n",
    "            running_loss += total_loss.item()\n",
    "            _, predicted = torch.max(outputs_class, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_weight_preds.extend(outputs_weight.cpu().numpy())\n",
    "            all_weight_true.extend(weights.cpu().numpy())\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    mae = mean_absolute_error(all_weight_true, all_weight_preds)\n",
    "    return avg_loss, accuracy, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3788c",
   "metadata": {},
   "source": [
    "## 7. Model Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ed659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, avg_val_loss, val_accuracy, val_mae, label_to_idx, model_path, epoch, score):\n",
    "    \"\"\"Helper function to save a model checkpoint\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_mae': val_mae,\n",
    "        'composite_score': score,\n",
    "        'label_to_idx': label_to_idx\n",
    "    }, model_path)\n",
    "    return model_path\n",
    "\n",
    "def save_best_model(model, optimizer, avg_val_loss, val_accuracy, val_mae, label_to_idx, model_save_dir, epoch):\n",
    "    \"\"\"\n",
    "    Save the best model based on a composite score of accuracy and MAE.\n",
    "    Returns whether a model was saved and the current score.\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(model_save_dir, \"best_model.pth\")\n",
    "    save_model_flag = False\n",
    "    prev_val_accuracy = 0\n",
    "    prev_val_loss = float('inf')\n",
    "    prev_val_mae = float('inf')\n",
    "    prev_score = -float('inf')\n",
    "    current_score = val_accuracy - (val_mae / 100)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            prev_ckpt = torch.load(model_path, map_location='cpu')\n",
    "            prev_val_accuracy = prev_ckpt.get('val_accuracy', 0)\n",
    "            prev_val_loss = prev_ckpt.get('val_loss', float('inf'))\n",
    "            prev_val_mae = prev_ckpt.get('val_mae', float('inf'))\n",
    "            if epoch == 0:\n",
    "                print(f\"Found existing model with val_loss={prev_val_loss:.4f}, val_accuracy={prev_val_accuracy:.4f}, val_mae={prev_val_mae:.2f}g\")\n",
    "            \n",
    "            # Composite score: Higher accuracy is better, lower MAE is better\n",
    "            # Scale MAE to be roughly in the same range as accuracy (0-1)\n",
    "            prev_score = prev_val_accuracy - (prev_val_mae / 100)\n",
    "            \n",
    "            if current_score > prev_score:\n",
    "                save_model_flag = True\n",
    "                print(f\"Better combined score: {current_score:.4f} vs {prev_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"Worse combined score: {current_score:.4f} vs {prev_score:.4f} - not saving\")\n",
    "                \n",
    "            # Fallback to accuracy-only comparison if scores are very close\n",
    "            if not save_model_flag and val_accuracy > prev_val_accuracy * 1.05:\n",
    "                save_model_flag = True\n",
    "                print(f\"Significantly better accuracy: {val_accuracy:.4f} vs {prev_val_accuracy:.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load previous checkpoint for comparison: {e}\")\n",
    "            save_model_flag = True\n",
    "    else:\n",
    "        save_model_flag = True\n",
    "        print(\"No previous model found, saving first model\")\n",
    "    \n",
    "    if save_model_flag:\n",
    "        save_model(model, optimizer, avg_val_loss, val_accuracy, val_mae, label_to_idx, model_path, epoch, current_score)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "    else:\n",
    "        print(f\"Model not saved (composite score {current_score:.4f} <= previous {prev_score:.4f})\")\n",
    "        \n",
    "    return save_model_flag, current_score\n",
    "\n",
    "def manage_topn_models(model, optimizer, avg_val_loss, val_accuracy, val_mae, label_to_idx, \n",
    "                      model_save_dir, epoch, current_score, top_n_models, save_top_n):\n",
    "    \"\"\"\n",
    "    Manage saving top-N models - returns the updated list of top models\n",
    "    \"\"\"\n",
    "    model_path_base = os.path.join(model_save_dir, f\"model_epoch_{epoch+1}\")\n",
    "    model_path = f\"{model_path_base}.pth\"\n",
    "    \n",
    "    # Keep track of top models \n",
    "    if len(top_n_models) < save_top_n or current_score > top_n_models[-1][0]:\n",
    "        # Save this model as one of the top-N\n",
    "        save_model(model, optimizer, avg_val_loss, val_accuracy, val_mae, label_to_idx, model_path, epoch, current_score)\n",
    "        \n",
    "        # Add to list and sort\n",
    "        top_n_models.append((current_score, epoch, model_path))\n",
    "        top_n_models.sort(reverse=True)  # Sort by score (highest first)\n",
    "        \n",
    "        # If we have more than N models, remove the worst one\n",
    "        if len(top_n_models) > save_top_n:\n",
    "            _, _, old_path = top_n_models.pop()  # Remove the lowest score model\n",
    "            if os.path.exists(old_path):\n",
    "                try:\n",
    "                    os.remove(old_path)\n",
    "                    print(f\"Removed model with lower score: {old_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing old model file: {e}\")\n",
    "        \n",
    "        print(f\"Saved as a top-{min(len(top_n_models), save_top_n)} model with score {current_score:.4f}\")\n",
    "    \n",
    "    return top_n_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efd39f",
   "metadata": {},
   "source": [
    "## 8. Early Stopping and Checkpoint Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_early_stopping(current_score, best_score, best_epoch, no_improve_count, patience, optimizer, lr_strategy, scheduler, epoch):\n",
    "    \"\"\"\n",
    "    Handle early stopping logic and adaptive learning rate adjustments.\n",
    "    Returns: best_score, best_epoch, no_improve_count, should_stop\n",
    "    \"\"\"\n",
    "    should_stop = False\n",
    "    \n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        best_epoch = epoch\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        \n",
    "    # Adapting scheduler based on stagnation for non-one-cycle strategies\n",
    "    if no_improve_count > 0 and lr_strategy != 'one_cycle' and scheduler is not None:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Reduce LR more aggressively if we're stagnating\n",
    "        if no_improve_count >= patience // 2:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_lr * 0.5\n",
    "            print(f\"Reducing learning rate to {optimizer.param_groups[0]['lr']} due to stagnation\")\n",
    "            \n",
    "    print(f\"Current best: epoch {best_epoch+1} with score {best_score:.4f}, no improvement for {no_improve_count} epochs\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if no_improve_count >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1} after {patience} epochs without improvement\")\n",
    "        print(f\"Best performance was at epoch {best_epoch+1}\")\n",
    "        should_stop = True\n",
    "    \n",
    "    return best_score, best_epoch, no_improve_count, should_stop\n",
    "\n",
    "def resume_from_checkpoint(model, optimizer, model_save_dir, device):\n",
    "    \"\"\"\n",
    "    Attempt to resume training from a saved checkpoint.\n",
    "    Returns: start_epoch (0 if no valid checkpoint)\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    model_path = os.path.join(model_save_dir, \"best_model.pth\")\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint.get('epoch', 0) + 1  # Start from the next epoch\n",
    "            print(f\"Resuming from epoch {start_epoch+1}, checkpoint accuracy: {checkpoint.get('val_accuracy', 0):.4f}\")\n",
    "            return start_epoch\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load checkpoint for resuming: {e}\")\n",
    "    \n",
    "    print(\"No valid checkpoint found. Starting from epoch 1.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9203108",
   "metadata": {},
   "source": [
    "## 9. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(logs, plots_dir):\n",
    "    \"\"\"Plot and save training metrics history\"\"\"\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(logs[\"epochs\"], logs[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(logs[\"epochs\"], logs[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_dir, \"loss_history.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Accuracy and MAE\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy', color=color)\n",
    "    ax1.plot(logs[\"epochs\"], logs[\"val_accuracy\"], color=color, label=\"Accuracy\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  # Create a second y-axis\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('MAE (g)', color=color)\n",
    "    ax2.plot(logs[\"epochs\"], logs[\"weight_mae\"], color=color, label=\"MAE\")\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Validation Accuracy and Weight MAE\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_dir, \"accuracy_mae_history.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot composite score\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(logs[\"epochs\"], logs[\"scores\"], marker='o')\n",
    "    plt.title(\"Model Performance Score\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Score (Accuracy - MAE/100)\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_dir, \"score_history.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906d12b",
   "metadata": {},
   "source": [
    "## 10. Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, device, num_epochs, model_save_dir, \n",
    "              lr_strategy='one_cycle', lr=1e-4, patience=5, save_top_n=3, resume=False):\n",
    "    \"\"\"\n",
    "    Train the model with advanced features like early stopping, top-N model saving,\n",
    "    and checkpoint resuming.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to train\n",
    "        train_dataloader: DataLoader for training data\n",
    "        val_dataloader: DataLoader for validation data\n",
    "        device: Device to use for training\n",
    "        num_epochs: Number of epochs to train for\n",
    "        model_save_dir: Directory to save the model\n",
    "        lr_strategy: Learning rate strategy ('one_cycle', 'cosine', 'step')\n",
    "        lr: Learning rate\n",
    "        patience: Number of epochs to wait for improvement before early stopping\n",
    "        save_top_n: Number of best models to save\n",
    "        resume: Whether to resume training from a checkpoint\n",
    "    \n",
    "    Returns:\n",
    "        training_logs: Dictionary containing training metrics\n",
    "    \"\"\"\n",
    "    # Loss functions\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_weight = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Attempt to resume from checkpoint if requested\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        start_epoch = resume_from_checkpoint(model, optimizer, model_save_dir, device)\n",
    "    \n",
    "    # Initialize scheduler after potential resume\n",
    "    steps_per_epoch = len(train_dataloader)\n",
    "    scheduler = get_scheduler(optimizer, lr_strategy, num_epochs, steps_per_epoch, lr)\n",
    "    \n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Optimizer: Adam, lr={lr}\")\n",
    "    print(f\"Scheduler: {lr_strategy}\")\n",
    "    print(f\"Early stopping patience: {patience}, save top {save_top_n} models\")\n",
    "    print(f\"Starting training from epoch {start_epoch+1} to {num_epochs}...\")\n",
    "    \n",
    "    # Initialize early stopping variables\n",
    "    best_score = float('-inf')\n",
    "    best_epoch = 0\n",
    "    no_improve_count = 0\n",
    "    \n",
    "    # Initialize model saving variables for top-N models\n",
    "    top_n_models = []  # Will store (score, epoch, path) tuples\n",
    "\n",
    "    # Metrics tracking\n",
    "    training_logs = {\n",
    "        \"epochs\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": [],\n",
    "        \"weight_mae\": [],\n",
    "        \"scores\": []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        # Training phase\n",
    "        avg_train_loss = _train_one_epoch(\n",
    "            model, train_dataloader, optimizer, scheduler, \n",
    "            device, criterion_class, criterion_weight, lr_strategy\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        avg_val_loss, val_accuracy, val_mae = _validate_one_epoch(\n",
    "            model, val_dataloader, device, criterion_class, criterion_weight\n",
    "        )\n",
    "        \n",
    "        # Calculate composite score\n",
    "        current_score = val_accuracy - (val_mae / 100)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss = {avg_val_loss:.4f}, \"\n",
    "              f\"Val Acc = {val_accuracy:.4f}, Weight MAE = {val_mae:.2f}g, \"\n",
    "              f\"Score = {current_score:.4f}\")\n",
    "        \n",
    "        # Save epoch metrics to log\n",
    "        training_logs[\"epochs\"].append(epoch + 1)\n",
    "        training_logs[\"train_loss\"].append(avg_train_loss)\n",
    "        training_logs[\"val_loss\"].append(avg_val_loss)\n",
    "        training_logs[\"val_accuracy\"].append(val_accuracy)\n",
    "        training_logs[\"weight_mae\"].append(val_mae)\n",
    "        training_logs[\"scores\"].append(current_score)\n",
    "\n",
    "        # Safely extract label mapping\n",
    "        label_df = getattr(train_dataloader.dataset.dataset, 'df', None)\n",
    "        if label_df is not None:\n",
    "            label_to_idx = {label: idx for idx, label in enumerate(label_df['labels'].unique())}\n",
    "        else:\n",
    "            label_to_idx = {}\n",
    "        \n",
    "        # Save best model\n",
    "        _, _ = save_best_model(\n",
    "            model, optimizer, avg_val_loss, val_accuracy, val_mae,\n",
    "            label_to_idx, model_save_dir, epoch\n",
    "        )\n",
    "        \n",
    "        # Manage top-N models\n",
    "        top_n_models = manage_topn_models(\n",
    "            model, optimizer, avg_val_loss, val_accuracy, val_mae,\n",
    "            label_to_idx, model_save_dir, epoch, current_score,\n",
    "            top_n_models, save_top_n\n",
    "        )\n",
    "        \n",
    "        # Handle early stopping\n",
    "        best_score, best_epoch, no_improve_count, should_stop = handle_early_stopping(\n",
    "            current_score, best_score, best_epoch, no_improve_count,\n",
    "            patience, optimizer, lr_strategy, scheduler, epoch\n",
    "        )\n",
    "        \n",
    "        if should_stop:\n",
    "            break\n",
    "        \n",
    "        # Step the scheduler for epoch-based schedulers\n",
    "        if scheduler is not None and lr_strategy != 'one_cycle':\n",
    "            scheduler.step()\n",
    "\n",
    "    # Print top-N model summary\n",
    "    print(\"\\nTop models summary:\")\n",
    "    for i, (score, ep, path) in enumerate(top_n_models):\n",
    "        print(f\"{i+1}. Epoch {ep+1}: score={score:.4f}, saved at {path}\")\n",
    "    \n",
    "    # Save a model summary JSON with info about the top models\n",
    "    models_summary = {\n",
    "        \"best_model\": {\n",
    "            \"epoch\": best_epoch + 1,\n",
    "            \"score\": float(best_score) \n",
    "        },\n",
    "        \"top_models\": [\n",
    "            {\"epoch\": e+1, \"score\": float(s), \"path\": p} for s, e, p in top_n_models\n",
    "        ],\n",
    "        \"training_completed\": True,\n",
    "        \"early_stopped\": no_improve_count >= patience,\n",
    "        \"total_epochs_trained\": epoch + 1\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(model_save_dir, \"models_summary.json\"), \"w\") as f:\n",
    "        json.dump(models_summary, f, indent=4)\n",
    "\n",
    "    # Create a training plots directory\n",
    "    plots_dir = os.path.join(model_save_dir, 'plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(training_logs, plots_dir)\n",
    "    \n",
    "    return training_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfdc43",
   "metadata": {},
   "source": [
    "## 11. Training Configuration (Edit as Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your training parameters here\n",
    "# You can adjust these parameters as needed for your specific setup\n",
    "\n",
    "# Colab/Kaggle specific paths\n",
    "# For Colab, you might need to adapt these based on where you upload your data\n",
    "# For Kaggle, these should match your notebook environment\n",
    "\n",
    "# When running locally, you might use something like:\n",
    "#csv_path = \"/Users/chalkiasantonios/Desktop/master-thesis/csvfiles/labels.csv\"\n",
    "#images_dir = \"/Users/chalkiasantonios/Desktop/master-thesis/image_set_2\"\n",
    "#model_save_dir = \"/Users/chalkiasantonios/Desktop/master-thesis/models\"\n",
    "\n",
    "# For Google Colab, you might use:\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (uncomment if needed)\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Define paths (edit as needed for your environment)\n",
    "# Kaggle paths\n",
    "USE_KAGGLE = True  # Set to False if using Colab or local environment\n",
    "\n",
    "if USE_KAGGLE:\n",
    "    master_thesis_dir = \"/kaggle/working\"\n",
    "    data_path = \"/kaggle/input/data-set-labeld-weights\"\n",
    "    csv_path = os.path.join(data_path, \"labels.csv\")\n",
    "    images_dir = os.path.join(data_path, \"image_set_2\")\n",
    "else:\n",
    "    # Local or Colab paths\n",
    "    master_thesis_dir = \"/Users/chalkiasantonios/Desktop/master-thesis\"\n",
    "    csv_path = os.path.join(master_thesis_dir, \"csvfiles\", \"labels.csv\")\n",
    "    images_dir = os.path.join(master_thesis_dir, \"image_set_2\")\n",
    "\n",
    "model_save_dir = os.path.join(master_thesis_dir, \"models\")\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "lr_strategy = 'cosine'  # 'one_cycle', 'cosine', or 'step'\n",
    "patience = 7\n",
    "save_top_n = 3\n",
    "resume = False\n",
    "num_workers = 2  # Adjust based on your CPU cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc6556",
   "metadata": {},
   "source": [
    "## 12. Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print configuration\n",
    "print(f\"CSV path: {csv_path}\")\n",
    "print(f\"Images directory: {images_dir}\")\n",
    "print(f\"Model save directory: {model_save_dir}\")\n",
    "print(f\"Training parameters: epochs={num_epochs}, batch_size={batch_size}, lr={lr}\")\n",
    "print(f\"LR strategy: {lr_strategy}, patience: {patience}, save top {save_top_n} models\")\n",
    "\n",
    "# Prepare data\n",
    "train_dataloader, val_dataloader, label_to_idx = prepare_data(\n",
    "    csv_path, \n",
    "    images_dir, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "num_classes = len(label_to_idx)\n",
    "model = MultiTaskNet(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "training_logs = train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    device, \n",
    "    num_epochs, \n",
    "    model_save_dir,\n",
    "    lr_strategy=lr_strategy,\n",
    "    lr=lr,\n",
    "    patience=patience,\n",
    "    save_top_n=save_top_n,\n",
    "    resume=resume\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5357bc7",
   "metadata": {},
   "source": [
    "## 13. Evaluation and Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training results if available\n",
    "plots_dir = os.path.join(model_save_dir, 'plots')\n",
    "if os.path.exists(plots_dir):\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    print(\"Training Loss History:\")\n",
    "    display(Image(os.path.join(plots_dir, \"loss_history.png\")))\n",
    "    \n",
    "    print(\"\\nAccuracy and MAE:\")\n",
    "    display(Image(os.path.join(plots_dir, \"accuracy_mae_history.png\")))\n",
    "    \n",
    "    print(\"\\nComposite Score:\")\n",
    "    display(Image(os.path.join(plots_dir, \"score_history.png\")))\n",
    "else:\n",
    "    print(\"No training plots found. Run the training cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cfdcf",
   "metadata": {},
   "source": [
    "## 14. Load and Test the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdebc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model_save_dir, device, num_classes):\n",
    "    \"\"\"Load the best model from the saved checkpoint\"\"\"\n",
    "    model_path = os.path.join(model_save_dir, \"best_model.pth\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"No model found at {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create a new model instance\n",
    "    model = MultiTaskNet(num_classes)\n",
    "    \n",
    "    try:\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"Loaded model from epoch {checkpoint.get('epoch', 0) + 1}\")\n",
    "        print(f\"Validation metrics:\")\n",
    "        print(f\"- Accuracy: {checkpoint.get('val_accuracy', 0):.4f}\")\n",
    "        print(f\"- MAE: {checkpoint.get('val_mae', 0):.2f}g\")\n",
    "        print(f\"- Score: {checkpoint.get('composite_score', 0):.4f}\")\n",
    "        \n",
    "        return model, checkpoint.get('label_to_idx', {})\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load the best model for testing\n",
    "best_model, label_map = load_best_model(model_save_dir, device, num_classes)\n",
    "\n",
    "if best_model is not None:\n",
    "    print(\"\\nBest model loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\nFailed to load model. Make sure training has completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
